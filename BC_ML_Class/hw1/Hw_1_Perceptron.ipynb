{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import neccesary packages\n",
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "dataset_1 = np.loadtxt('sampleData1.txt',delimiter=',')\n",
    "(numSamples_1, numFeatures_1) = dataset_1.shape\n",
    "data_1 = dataset_1[:,range(2)].reshape((numSamples_1, 2))\n",
    "labels_1 = dataset_1[:, 2].reshape((numSamples_1,))\n",
    "\n",
    "dataset_2 = np.loadtxt('sampleData2.txt',delimiter=',')\n",
    "(numSamples_2, numFeatures_2) = dataset_2.shape\n",
    "data_2 = dataset_2[:,range(2)].reshape((numSamples_2, 2))\n",
    "labels_2 = dataset_2[:, 2].reshape((numSamples_2,))\n",
    "\n",
    "dataset_3 = np.loadtxt('sampleData3.txt',delimiter=',')\n",
    "(numSamples_3, numFeatures_3) = dataset_3.shape\n",
    "data_3 = dataset_3[:,range(2)].reshape((numSamples_3, 2))\n",
    "labels_3 = dataset_3[:, 2].reshape((numSamples_3,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load perceptron\n",
    "#generate stop counter\n",
    "#generate counter to track weight changes \n",
    "def partial_1():\n",
    "    perceptron_1 = Perceptron()\n",
    "    stop_1 = 0\n",
    "    counter_1 = 0\n",
    "    while stop_1 == 0:\n",
    "        for x in range(1000):\n",
    "            perceptron_1.partial_fit([data_1[x]],[labels_1[x]], classes= np.unique(labels_1))\n",
    "            if perceptron_1.score(data_1,labels_1) == 1:\n",
    "                counter_1 +=1\n",
    "                stop_1 +=1\n",
    "                break\n",
    "            else:\n",
    "                counter_1 +=1\n",
    "    weights = perceptron_1.coef_\n",
    "    w1 = weights[0][0]\n",
    "    w2 = weights[0][1]\n",
    "    w0 = perceptron_1.intercept_[0]\n",
    "    print(\"Weights was adjusted {} times\".format(counter_1))\n",
    "    print(\"Intercept (w0) is {}\".format(w0))\n",
    "    print(\"Final weight vector is : {} Hence:\".format(weights))\n",
    "    print(\"w1 is : {}  , w2 weight is: {}\".format(w1, w2))\n",
    "    #deriving the line based on HW Problem 1.2\n",
    "    a = -1* (w1/w2)\n",
    "    b = -1* (w0/w2)\n",
    "    print(\"The equation of the decision boundary  line is y = ({})x + ({})\".format(a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_2():\n",
    "    perceptron_2 = Perceptron()\n",
    "    stop_2 = 0\n",
    "    counter_2 = 0\n",
    "    while stop_2 == 0:\n",
    "        for x in range(1000):\n",
    "            perceptron_2.partial_fit([data_2[x]],[labels_2[x]], classes= np.unique(labels_2))\n",
    "            if perceptron_2.score(data_2,labels_2) == 1:\n",
    "                counter_2 +=1\n",
    "                stop_2 +=1\n",
    "                break\n",
    "            else:\n",
    "                counter_2 +=1\n",
    "    weights = perceptron_2.coef_\n",
    "    w1 = weights[0][0]\n",
    "    w2 = weights[0][1]\n",
    "    w0 = perceptron_2.intercept_[0]\n",
    "    print(\"Weights was adjusted {} times\".format(counter_2))\n",
    "    print(\"Intercept (w0) is {}\".format(w0))\n",
    "    print(\"Final weight vector is : {} Hence:\".format(weights))\n",
    "    print(\"w1 is : {}  , w2 weight is: {}\".format(w1, w2))\n",
    "    #deriving the line based on HW Problem 1.2\n",
    "    a = -1* (w1/w2)\n",
    "    b = -1* (w0/w2)\n",
    "    print(\"The equation of the decision boundary line is y = ({})x + ({})\".format(a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_3():\n",
    "    perceptron_3 = Perceptron()\n",
    "    stop_3 = 0\n",
    "    counter_3 = 0\n",
    "    while stop_3 == 0:\n",
    "        for x in range(1000):\n",
    "            perceptron_3.partial_fit([data_3[x]],[labels_3[x]], classes= np.unique(labels_3))\n",
    "            if perceptron_3.score(data_3,labels_3) == 1:\n",
    "                stop_3 +=1\n",
    "            if counter_3 >= 100000:\n",
    "                return print('No Convergence')\n",
    "            else:\n",
    "                counter_3 +=1\n",
    "    weights = perceptron_3.coef_\n",
    "    w1 = weights[0][0]\n",
    "    w2 = weights[0][1]\n",
    "    w0 = perceptron_3.intercept_[0]\n",
    "    print(\"Weights was adjusted {} times\".format(counter_3))\n",
    "    print(\"Intercept (w0) is {}\".format(w0))\n",
    "    print(\"Final weight vector is : {} Hence:\".format(weights))\n",
    "    print(\"w1 is : {}  , w2 weight is: {}\".format(w1, w2))\n",
    "    #deriving the line based on HW Problem 1.2\n",
    "    a = -1* (w1/w2)\n",
    "    b = -1* (w0/w2)\n",
    "    print(\"The equation of the decision boundary line is y = ({})x + ({})\".format(a,b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main differences:\n",
    "\n",
    "sampleData3.txt did not converge, which indicates that the points plotted on to a cartesians plane cannot be seperated by a linear line.\n",
    "\n",
    "As for the main differences between sampleData2.txt and sampleData1.txt, due to the high volume of adjustments in sampleData2.txt, we can assume that the points of true classification and false classifications are tightly plotted. This would account for why the weights had to be adjusted so many times.\n",
    "\n",
    "w2 has consistently been greater than w1 for the data we tested, which may mean that the second feature played a higher role in determinging the right classification. This seemed to be especially true for sampleData2.txt, with the intercept being 14, we can assume that the line is much higher, which would also explain the high volume of weight adjustments since adjustments are only increased or decreased by a minimal value.\n",
    "\n",
    "The likely reason why sample_3 doesn't converge is because there doesn't exist a linear line such that positive and negative feedbacks can be distinctly seperated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights was adjusted 957 times\n",
      "Intercept (w0) is 2.0\n",
      "Final weight vector is : [[ 6.974976 10.593447]] Hence:\n",
      "w1 is : 6.974976000000002  , w2 weight is: 10.593447\n",
      "The equation of the decision boundary  line is y = (-0.6584236462409263)x + (-0.18879596037059515)\n"
     ]
    }
   ],
   "source": [
    "#Sample 1:\n",
    "partial_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights was adjusted 56589 times\n",
      "Intercept (w0) is 14.0\n",
      "Final weight vector is : [[28.51788  42.613589]] Hence:\n",
      "w1 is : 28.51788000000003  , w2 weight is: 42.6135890000001\n",
      "The equation of the decision boundary line is y = (-0.6692203278160862)x + (-0.32853369848758734)\n"
     ]
    }
   ],
   "source": [
    "#Sample 2:\n",
    "partial_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Convergence\n"
     ]
    }
   ],
   "source": [
    "#Sample 3:\n",
    "partial_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
